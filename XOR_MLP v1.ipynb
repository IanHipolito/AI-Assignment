{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22/11/2019\n",
    "\n",
    "The code here is close to Nielsen. Each activation is treated as a column vector, even the last one which for XOR is just a simple number and is encloded in a shape (1,1) column vector of just one row, i.e if activation value of output neuron is a, then it is computed as np.array([[a]]).\n",
    "\n",
    "Can easily adapt code here for the MLP excercises and the Iris classification problem.\n",
    "But you may need to use more than 2 hidden neurons and more than 1 output neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigm(z):\n",
    "    return  1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def sigm_deriv(z):\n",
    "    a = sigm(z)\n",
    "    return a*(1 - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR_MLP:\n",
    "    def __init__(self):\n",
    "        self.train_inputs = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "        self.train_outputs = np.array([0,1,1,0])\n",
    "          \n",
    "        np.random.seed(23)\n",
    "        # hidden layer of 2 neurons\n",
    "        self.w2 = np.random.randn(2,2)\n",
    "        self.b2 = np.random.randn(2,1)\n",
    "        \n",
    "        # output layer has 1 neuron\n",
    "        self.w3 = np.random.randn(1,2)\n",
    "        self.b3 = np.random.randn(1,1)\n",
    "        \n",
    "\n",
    "    def feedforward(self, xs):    \n",
    "        # here xs is a matrix where each column is an input vector\n",
    "        # w2.dot(xs) applies the weight matrix w2 to each input at once\n",
    "        a2s = sigm(self.w2.dot(xs) + self.b2)\n",
    "        a3s = sigm(self.w3.dot(a2s) + self.b3)            \n",
    "        return a3s\n",
    "\n",
    "    \n",
    "    def backprop(self, xs, ys):   # Assumed here that input vectors are rows in xs\n",
    "        del_w2 = np.zeros(self.w2.shape, dtype=float)\n",
    "        del_b2 = np.zeros(self.b2.shape, dtype=float)\n",
    "        \n",
    "        del_w3 = np.zeros(self.w3.shape, dtype=float)\n",
    "        del_b3 = np.zeros(self.b3.shape, dtype=float)\n",
    "        cost = 0.0\n",
    "        \n",
    "        for x,y in zip(xs,ys):               # for zip to work, each x in xs must be a row vector\n",
    "            a1 = x.reshape(2,1)              # convert input row vector x into (2,1) column vector\n",
    "            z2 = self.w2.dot(a1) + self.b2   # so will z2 and a2\n",
    "            a2 = sigm(z2)                    # column vector shape (2,1)\n",
    "            \n",
    "            z3 = self.w3.dot(a2) + self.b3   # a simple number in a (1,1) column vector\n",
    "            a3 = sigm(z3)                    # so is a3\n",
    "            \n",
    "            delta3 = (a3-y) * sigm_deriv(z3)                   # delta3.shape is (1,1)\n",
    "           \n",
    "            delta2 = sigm_deriv(z2) * (self.w3.T.dot(delta3))  # w3 shape is (1,2), w3.T shape is (2,1)\n",
    "                                                               # delta2 is shape (2,1)\n",
    "            del_b3 += delta3\n",
    "            del_w3 += delta3.dot(a2.T)  # shape (1,1) by (1,2) gives (1,2)\n",
    "            \n",
    "            del_b2 += delta2\n",
    "            del_w2 += delta2.dot(a1.T)  # shape (2,1) by (1,2) gives (2,2)\n",
    "        \n",
    "           \n",
    "            cost += ((a3 - y)**2).sum() \n",
    "        \n",
    "        n = len(ys)  # number of training vectors    \n",
    "        \n",
    "        # get the average change per training input  \n",
    "        # return the average adjustments to the biases and weights \n",
    "        # in each layer and the cost\n",
    "        return del_b2/n, del_w2/n, del_b3/n, del_w3/n, cost/n\n",
    "        \n",
    "    def train(self, epochs, eta):\n",
    "        xs = self.train_inputs\n",
    "        ys = self.train_outputs\n",
    "        cost = np.zeros((epochs,))\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            d_b2,d_w2,d_b3,d_w3, cost[e] = self.backprop(xs,ys)\n",
    "                \n",
    "            self.b2 -= eta * d_b2\n",
    "            self.w2 -= eta * d_w2\n",
    "            self.b3 -= eta * d_b3\n",
    "            self.w3 -= eta * d_w3\n",
    "        plt.plot(cost)\n",
    "        return cost\n",
    "                \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor = XOR_MLP()\n",
    "xs = xor.train_inputs.T\n",
    "\n",
    "print(xor.feedforward(xs))\n",
    "\n",
    "epochs = 1000\n",
    "c = xor.train(epochs, 3.0)\n",
    "\n",
    "print(xor.feedforward(xs))\n",
    "\n",
    "x_axis = np.linspace(1, epochs, epochs, dtype=int)\n",
    "fig, axs = plt.subplots(3,1,figsize=(10,15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x_axis, c)\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x_axis[:61], c[:61])\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(x_axis[900:], c[900:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: copy and adapt the above XOR_MLP code so that it uses 3 neurons in the hidden layer. Train such a MLP and see if it learns faster than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "class XOR_MLP_COPY:\n",
    "    def __init__(self):\n",
    "        self.train_inputs = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "        self.train_outputs = np.array([0,1,1,0])\n",
    "          \n",
    "        np.random.seed(23)\n",
    "        # hidden layer of 2 neurons\n",
    "        self.w2 = np.random.randn(3,2)\n",
    "        self.b2 = np.random.randn(3,1)\n",
    "        \n",
    "        # output layer has 1 neuron\n",
    "        self.w3 = np.random.randn(1,3)\n",
    "        self.b3 = np.random.randn(1,1)\n",
    "        \n",
    "\n",
    "    def feedforward(self, xs):    \n",
    "        # here xs is a matrix where each column is an input vector\n",
    "        # w2.dot(xs) applies the weight matrix w2 to each input at once\n",
    "        a2s = sigm(self.w2.dot(xs) + self.b2)\n",
    "        a3s = sigm(self.w3.dot(a2s) + self.b3)            \n",
    "        return a3s\n",
    "\n",
    "    \n",
    "    def backprop(self, xs, ys):   # Assumed here that input vectors are rows in xs\n",
    "        del_w2 = np.zeros(self.w2.shape, dtype=float)\n",
    "        del_b2 = np.zeros(self.b2.shape, dtype=float)\n",
    "        \n",
    "        del_w3 = np.zeros(self.w3.shape, dtype=float)\n",
    "        del_b3 = np.zeros(self.b3.shape, dtype=float)\n",
    "        cost = 0.0\n",
    "        \n",
    "        for x,y in zip(xs,ys):               # for zip to work, each x in xs must be a row vector\n",
    "            a1 = x.reshape(2,1)              # convert input row vector x into (2,1) column vector\n",
    "            z2 = self.w2.dot(a1) + self.b2   # so will z2 and a2\n",
    "            a2 = sigm(z2)                    # column vector shape (2,1)\n",
    "            \n",
    "            z3 = self.w3.dot(a2) + self.b3   # a simple number in a (1,1) column vector\n",
    "            a3 = sigm(z3)                    # so is a3\n",
    "            \n",
    "            delta3 = (a3-y) * sigm_deriv(z3)                   # delta3.shape is (1,1)\n",
    "           \n",
    "            delta2 = sigm_deriv(z2) * (self.w3.T.dot(delta3))  # w3 shape is (1,2), w3.T shape is (2,1)\n",
    "                                                               # delta2 is shape (2,1)\n",
    "            del_b3 += delta3\n",
    "            del_w3 += delta3.dot(a2.T)  # shape (1,1) by (1,2) gives (1,2)\n",
    "            \n",
    "            del_b2 += delta2\n",
    "            del_w2 += delta2.dot(a1.T)  # shape (2,1) by (1,2) gives (2,2)\n",
    "        \n",
    "           \n",
    "            cost += ((a3 - y)**2).sum() \n",
    "        \n",
    "        n = len(ys)  # number of training vectors    \n",
    "        \n",
    "        # get the average change per training input  \n",
    "        # return the average adjustments to the biases and weights \n",
    "        # in each layer and the cost\n",
    "        return del_b2/n, del_w2/n, del_b3/n, del_w3/n, cost/n\n",
    "        \n",
    "    def train(self, epochs, eta):\n",
    "        xs = self.train_inputs\n",
    "        ys = self.train_outputs\n",
    "        cost = np.zeros((epochs,))\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            d_b2,d_w2,d_b3,d_w3, cost[e] = self.backprop(xs,ys)\n",
    "                \n",
    "            self.b2 -= eta * d_b2\n",
    "            self.w2 -= eta * d_w2\n",
    "            self.b3 -= eta * d_b3\n",
    "            self.w3 -= eta * d_w3\n",
    "        plt.plot(cost)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor2 = XOR_MLP_COPY()\n",
    "xs = xor2.train_inputs.T\n",
    "\n",
    "print(xor2.feedforward(xs))\n",
    "epochs = 1000\n",
    "c = xor2.train(epochs, 3.0)\n",
    "print(xor2.feedforward(xs))\n",
    "x_axis = np.linspace(1, epochs, epochs, dtype=int)\n",
    "\n",
    "fig, axs = plt.subplots(3,1,figsize=(10,15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x_axis, c)\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x_axis[:61], c[:61])\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(x_axis[900:], c[900:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more general purpose MLP with m input neurons, n hidden neurons and o output neurond\n",
    "# You must complete this code yourself\n",
    "class MLP:\n",
    "    def __init__(self, m, n, o):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.o = o\n",
    "          \n",
    "        np.random.seed(23)\n",
    "        # hidden layer of N neurons\n",
    "        self.w2 = np.random.randn(n,m)\n",
    "        self.b2 = np.random.randn(n,1)\n",
    "        \n",
    "        # output layer has O neurons but code is incorrect\n",
    "        # code here needs to be modified\n",
    "        self.w3 = np.random.randn(o,n)\n",
    "        self.b3 = np.random.randn(o,1)\n",
    "\n",
    "    def feedforward(self, xs):    \n",
    "        # here xs is a matrix where each column is an input vector\n",
    "        # w2.dot(xs) applies the weight matrix w2 to each input at once\n",
    "        a2s = sigm(self.w2.dot(xs) + self.b2)\n",
    "        a3s = sigm(self.w3.dot(a2s) + self.b3)   \n",
    "        # Format the output for better readability\n",
    "        formatted_output = self.format_output(a3s)\n",
    "        return formatted_output         \n",
    "    \n",
    "\n",
    "    \n",
    "    def backprop(self, xs, ys):\n",
    "        del_w2 = np.zeros(self.w2.shape, dtype=float)\n",
    "        del_b2 = np.zeros(self.b2.shape, dtype=float)\n",
    "        \n",
    "        del_w3 = np.zeros(self.w3.shape, dtype=float)\n",
    "        del_b3 = np.zeros(self.b3.shape, dtype=float)\n",
    "        cost = 0.0\n",
    "        \n",
    "        for x, y in zip(xs,ys):            \n",
    "            a1 = x.reshape(self.m, 1)        # convert input vector x into (2,1) column vector\n",
    "            y = y.reshape(self.o, 1)         # convert output vector y into (1,1) column vector\n",
    "\n",
    "\n",
    "            z2 = self.w2.dot(a1) + self.b2   # so will z2 and a2\n",
    "            a2 = sigm(z2)                    # column vector shape (2,1)\n",
    "            a2 = a2.reshape(self.n, 1)       # convert a2 into (2,1) column vector\n",
    "            \n",
    "            z3 = self.w3.dot(a2) + self.b3   # a simple number in a (1,1) column vector\n",
    "            a3 = sigm(z3)                    # so is a3\n",
    "            a3 = a3.reshape(self.o, 1)       # convert a3 into (1,1) column vector\n",
    "\n",
    "            delta3 = (a3-y) * sigm_deriv(z3)                   # delta3.shape is (1,1)\n",
    "           \n",
    "            delta2 = sigm_deriv(z2) * (self.w3.T.dot(delta3))  # w3 shape is (1,2), w3.T shape is (2,1)\n",
    "                                                               # delta2 is shape (2,1)\n",
    "            del_b3 += delta3\n",
    "            del_w3 += delta3.dot(a2.T)  # shape (1,1) by (1,2) gives (1,2)\n",
    "            \n",
    "            del_b2 += delta2\n",
    "            del_w2 += delta2.dot(a1.T)  # shape (2,1) by (1,2) gives (2,2)\n",
    "           \n",
    "            cost += ((a3 - y)**2).sum() \n",
    "        \n",
    "        n = len(ys)  # number of training vectors    \n",
    "        \n",
    "        # get the average change per training input  \n",
    "        # return the average adjustments to the biases and weights \n",
    "        # in each layer and the cost\n",
    "        return del_b2/n, del_w2/n, del_b3/n, del_w3/n, cost/n\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        return self.feedforward(xs)\n",
    "        \n",
    "    def train(self, epochs, eta):\n",
    "        cost = np.zeros((epochs,))\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            d_b2,d_w2,d_b3,d_w3, cost[e] = self.backprop(self.train_inputs ,self.train_outputs)\n",
    "                \n",
    "            self.b2 -= eta * d_b2\n",
    "            self.w2 -= eta * d_w2\n",
    "            self.b3 -= eta * d_b3\n",
    "            self.w3 -= eta * d_w3\n",
    "        plt.plot(cost)\n",
    "        plt.title('Loss Per Epochs/Iteration')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.show()\n",
    "        return cost\n",
    "                \n",
    "    def format_output(self, output):\n",
    "        formatted_output = \"\\n\".join(\n",
    "            \", \".join(f\"{value:.4f}\" for value in row) for row in output.T\n",
    "        )\n",
    "        return formatted_output\n",
    "                \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the outputs of these correct?\n",
    "p1 = MLP(3,4,2)\n",
    "print('\\n W2 = \\n',p1.w2, '\\n W3 = \\n', p1.w3, '\\n')\n",
    "\n",
    "p2 = MLP(4,6,3)\n",
    "print('\\n W2 = \\n', p2.w2, '\\nW3 = \\n', p2.w3, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 : Testing MLP\n",
    "p1_mlp = MLP(3,4,1)\n",
    "\n",
    "p1_mlp.train_inputs = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "p1_mlp.train_outputs = np.array([0,1,1,0])\n",
    "\n",
    "xs = p1_mlp.train_inputs.T\n",
    "\n",
    "print(\"\\nBefore Training:\\n\" + p1_mlp.feedforward(xs))\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "# The higher the learning rate the more unstale the grapgh is\n",
    "#learning_rate = 10.0\n",
    "learning_rate = 50.0\n",
    "\n",
    "c = p1_mlp.train(epochs, learning_rate)\n",
    "\n",
    "print(\"\\nAfter Training:\\n\" + p1_mlp.feedforward(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2 - Neural Network with 3 input and 2 output\n",
    "p2_mlp = MLP(3,4,2)\n",
    "\n",
    "p2_mlp.train_inputs = np.array([[1,1,0],\n",
    "                                [1,-1,-1],\n",
    "                                [-1,1,1],\n",
    "                                [-1,-1,1],\n",
    "                                [0,1,-1],\n",
    "                                [0,-1,-1],\n",
    "                                [1,1,1]])\n",
    "\n",
    "p2_mlp.train_outputs = np.array([[1,0],\n",
    "                                 [0,1],\n",
    "                                 [1,1],\n",
    "                                 [1,0],\n",
    "                                 [1,0],\n",
    "                                 [1,1],\n",
    "                                 [1,1]])\n",
    "\n",
    "xs = p2_mlp.train_inputs.T\n",
    "print(\"\\nBefore Training:\\n\" + p2_mlp.feedforward(xs))\n",
    "\n",
    "epochs = 2000\n",
    "learning_rate = 10.0\n",
    "\n",
    "c = p2_mlp.train(epochs, learning_rate)\n",
    "print(\"\\nAfter Training:\\n\" + p2_mlp.feedforward(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3 - Transportation Mode Choice\n",
    "# Possible Outputs: Bus [1,0,0] │ Train [0,1,0] │ Car [0,0,1]\n",
    "# Gender: 0 = Male │ 1 = Female\n",
    "# Car Ownership: 0 │ 1 │ 2 \n",
    "# Travel Costs: 0 = Cheap │ 1 = Standard │ 2 = Expensive\n",
    "# Income: 0 = Low │ 1 = Medium │ 2 = High\n",
    "\n",
    "p3_mlp = MLP(4,6,3)\n",
    "\n",
    "p3_mlp.train_inputs = np.array([[0,0,0,0], \n",
    "                                [0,1,0,1], \n",
    "                                [1,1,0,1], \n",
    "                                [1,0,0,0], \n",
    "                                [0,1,0,1], \n",
    "                                [0,0,1,1], \n",
    "                                [1,1,1,1], \n",
    "                                [1,1,2,2], \n",
    "                                [0,2,2,1], \n",
    "                                [1,2,2,2]])\n",
    "\n",
    "p3_mlp.train_outputs = np.array([[1,0,0], \n",
    "                                 [1,0,0], \n",
    "                                 [0,1,0], \n",
    "                                 [1,0,0], \n",
    "                                 [1,0,0], \n",
    "                                 [0,1,0], \n",
    "                                 [0,1,0], \n",
    "                                 [0,0,1], \n",
    "                                 [0,0,1], \n",
    "                                 [0,0,1]])\n",
    "\n",
    "xs = p3_mlp.train_inputs.T\n",
    "print(\"\\nBefore Training:\\n\" + p3_mlp.feedforward(xs))\n",
    "print(\"cost = \", str(c[-1]))\n",
    "\n",
    "epochs = 2000\n",
    "learning_rate = 10.0\n",
    "\n",
    "c = p3_mlp.train(epochs, learning_rate)\n",
    "print(\"\\nAfter Training:\\n\" + p3_mlp.feedforward(xs))\n",
    "print(\"cost = \", str(c[-1]))\n",
    "\n",
    "# Female Test Case: Car Ownership, Standard Travel Costs, medium Income\n",
    "print(\"\\nWomen Test Case:\")\n",
    "test_case = np.array([1, 1, 1, 1]).reshape(4,1)\n",
    "print(p3_mlp.predict(test_case))\n",
    "\n",
    "# Copying data to dataframe and saving it to a csv file seperated by commas\n",
    "p3_mlp_df = pd.DataFrame(p3_mlp.train_inputs)\n",
    "p3_mlp_df.to_csv('transport.csv', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and reading iris_data.csv into a dataframe\n",
    "df = pd.read_csv('iris_data.csv', header=None)\n",
    "\n",
    "#Last column is the output\n",
    "training_outputs = df.iloc[:,-1]\n",
    "\n",
    "#Converting the output to a one hot encoded vector\n",
    "training_outputs = pd.get_dummies(training_outputs)\n",
    "\n",
    "#Converting the dataframe to a numpy array\n",
    "training_outputs = training_outputs.to_numpy()\n",
    "\n",
    "#Convert y true and false to 1 and 0\n",
    "training_outputs = training_outputs.astype(int)\n",
    "\n",
    "#Drop last column from dataframe\n",
    "df = df.drop(df.columns[[-1]], axis=1)\n",
    "\n",
    "#Convert dataframe to numpy array\n",
    "training_inputs = df.to_numpy()\n",
    "\n",
    "#Clean up data\n",
    "training_inputs = training_inputs.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outputs Before Training:\n",
      "0.5609, 0.5688, 0.3651\n",
      "0.5338, 0.5684, 0.3431\n",
      "0.5606, 0.5653, 0.3601\n",
      "0.5570, 0.5604, 0.3526\n",
      "0.5715, 0.5666, 0.3712\n",
      "0.5742, 0.5649, 0.3596\n",
      "0.5791, 0.5600, 0.3628\n",
      "0.5578, 0.5666, 0.3599\n",
      "0.5544, 0.5586, 0.3481\n",
      "0.5342, 0.5687, 0.3529\n",
      "0.5597, 0.5708, 0.3668\n",
      "0.5655, 0.5617, 0.3611\n",
      "0.5319, 0.5691, 0.3518\n",
      "0.5621, 0.5643, 0.3683\n",
      "0.5648, 0.5751, 0.3797\n",
      "0.5912, 0.5672, 0.3797\n",
      "0.5822, 0.5676, 0.3696\n",
      "0.5659, 0.5669, 0.3594\n",
      "0.5552, 0.5710, 0.3562\n",
      "0.5800, 0.5647, 0.3700\n",
      "0.5358, 0.5707, 0.3478\n",
      "0.5782, 0.5635, 0.3602\n",
      "0.5908, 0.5648, 0.3852\n",
      "0.5593, 0.5581, 0.3283\n",
      "0.5614, 0.5553, 0.3540\n",
      "0.5269, 0.5664, 0.3367\n",
      "0.5654, 0.5611, 0.3450\n",
      "0.5552, 0.5693, 0.3611\n",
      "0.5488, 0.5712, 0.3585\n",
      "0.5577, 0.5602, 0.3534\n",
      "0.5460, 0.5622, 0.3463\n",
      "0.5508, 0.5686, 0.3402\n",
      "0.5868, 0.5663, 0.3890\n",
      "0.5861, 0.5687, 0.3867\n",
      "0.5342, 0.5687, 0.3529\n",
      "0.5452, 0.5717, 0.3563\n",
      "0.5409, 0.5760, 0.3600\n",
      "0.5342, 0.5687, 0.3529\n",
      "0.5619, 0.5607, 0.3557\n",
      "0.5531, 0.5683, 0.3581\n",
      "0.5713, 0.5665, 0.3633\n",
      "0.5086, 0.5579, 0.3005\n",
      "0.5741, 0.5603, 0.3656\n",
      "0.5766, 0.5570, 0.3364\n",
      "0.5736, 0.5583, 0.3543\n",
      "0.5471, 0.5637, 0.3382\n",
      "0.5759, 0.5649, 0.3730\n",
      "0.5644, 0.5621, 0.3598\n",
      "0.5640, 0.5694, 0.3684\n",
      "0.5518, 0.5685, 0.3573\n",
      "0.5502, 0.3239, 0.1838\n",
      "0.5652, 0.3202, 0.1863\n",
      "0.5632, 0.3117, 0.1741\n",
      "0.5776, 0.3063, 0.1636\n",
      "0.5732, 0.3073, 0.1623\n",
      "0.5712, 0.3085, 0.1935\n",
      "0.5717, 0.3132, 0.1884\n",
      "0.5611, 0.3462, 0.2045\n",
      "0.5523, 0.3179, 0.1811\n",
      "0.5845, 0.3135, 0.1864\n",
      "0.5578, 0.3199, 0.1770\n",
      "0.5752, 0.3181, 0.1830\n",
      "0.5285, 0.3223, 0.1718\n",
      "0.5705, 0.3078, 0.1845\n",
      "0.5656, 0.3497, 0.1970\n",
      "0.5546, 0.3279, 0.1818\n",
      "0.5815, 0.3065, 0.1926\n",
      "0.5430, 0.3304, 0.2055\n",
      "0.5875, 0.2935, 0.1355\n",
      "0.5544, 0.3251, 0.1887\n",
      "0.5923, 0.3001, 0.1776\n",
      "0.5585, 0.3305, 0.1812\n",
      "0.5860, 0.2950, 0.1528\n",
      "0.5581, 0.3110, 0.1943\n",
      "0.5536, 0.3254, 0.1828\n",
      "0.5578, 0.3232, 0.1778\n",
      "0.5607, 0.3090, 0.1661\n",
      "0.5848, 0.3006, 0.1585\n",
      "0.5776, 0.3080, 0.1770\n",
      "0.5385, 0.3623, 0.2001\n",
      "0.5563, 0.3244, 0.1841\n",
      "0.5457, 0.3342, 0.1919\n",
      "0.5568, 0.3314, 0.1886\n",
      "0.5957, 0.2925, 0.1645\n",
      "0.5850, 0.3043, 0.1979\n",
      "0.5725, 0.3180, 0.2001\n",
      "0.5646, 0.3146, 0.1762\n",
      "0.5613, 0.3048, 0.1519\n",
      "0.5665, 0.3254, 0.2048\n",
      "0.5750, 0.3119, 0.1754\n",
      "0.5709, 0.3067, 0.1934\n",
      "0.5675, 0.3123, 0.1893\n",
      "0.5584, 0.3231, 0.1830\n",
      "0.5574, 0.3438, 0.1954\n",
      "0.5717, 0.3127, 0.1869\n",
      "0.5590, 0.3265, 0.2106\n",
      "0.5666, 0.3198, 0.1968\n",
      "0.5576, 0.3229, 0.1867\n",
      "0.5623, 0.3777, 0.1990\n",
      "0.5673, 0.3204, 0.1900\n",
      "0.6339, 0.2794, 0.1370\n",
      "0.6185, 0.2846, 0.1465\n",
      "0.6171, 0.2850, 0.1331\n",
      "0.6039, 0.2892, 0.1603\n",
      "0.6257, 0.2820, 0.1356\n",
      "0.6192, 0.2829, 0.1324\n",
      "0.6193, 0.2850, 0.1639\n",
      "0.6011, 0.2883, 0.1497\n",
      "0.6155, 0.2821, 0.1349\n",
      "0.6194, 0.2862, 0.1365\n",
      "0.6020, 0.2946, 0.1527\n",
      "0.6145, 0.2856, 0.1374\n",
      "0.6165, 0.2863, 0.1341\n",
      "0.6323, 0.2791, 0.1307\n",
      "0.6470, 0.2750, 0.1203\n",
      "0.6235, 0.2851, 0.1363\n",
      "0.5973, 0.2927, 0.1603\n",
      "0.5919, 0.2957, 0.1646\n",
      "0.6480, 0.2710, 0.1073\n",
      "0.5998, 0.2866, 0.1442\n",
      "0.6227, 0.2845, 0.1312\n",
      "0.6223, 0.2846, 0.1471\n",
      "0.6196, 0.2812, 0.1294\n",
      "0.6052, 0.2908, 0.1419\n",
      "0.6056, 0.2908, 0.1531\n",
      "0.5883, 0.2955, 0.1634\n",
      "0.6024, 0.2935, 0.1480\n",
      "0.5971, 0.2961, 0.1620\n",
      "0.6266, 0.2812, 0.1322\n",
      "0.5783, 0.2977, 0.1653\n",
      "0.6089, 0.2856, 0.1340\n",
      "0.5776, 0.3016, 0.1721\n",
      "0.6331, 0.2791, 0.1261\n",
      "0.5812, 0.2985, 0.1714\n",
      "0.5914, 0.2899, 0.1802\n",
      "0.6302, 0.2800, 0.1150\n",
      "0.6230, 0.2847, 0.1451\n",
      "0.5947, 0.2941, 0.1680\n",
      "0.5976, 0.2967, 0.1632\n",
      "0.6120, 0.2889, 0.1364\n",
      "0.6335, 0.2803, 0.1231\n",
      "0.6263, 0.2850, 0.1222\n",
      "0.6185, 0.2846, 0.1465\n",
      "0.6233, 0.2837, 0.1346\n",
      "0.6322, 0.2812, 0.1271\n",
      "0.6303, 0.2824, 0.1214\n",
      "0.6198, 0.2835, 0.1269\n",
      "0.6097, 0.2898, 0.1429\n",
      "0.6168, 0.2876, 0.1522\n",
      "0.6003, 0.2930, 0.1687\n",
      "cost =  0.05063190217540465\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost =  0.05063190217540465\n",
      "\n",
      "Outputs after training:0.9718, 0.0475, 0.0041\n",
      "0.9594, 0.0630, 0.0047\n",
      "0.9702, 0.0505, 0.0041\n",
      "0.9632, 0.0602, 0.0045\n",
      "0.9736, 0.0457, 0.0040\n",
      "0.9718, 0.0476, 0.0041\n",
      "0.9720, 0.0489, 0.0040\n",
      "0.9688, 0.0518, 0.0042\n",
      "0.9612, 0.0633, 0.0046\n",
      "0.9604, 0.0620, 0.0047\n",
      "0.9721, 0.0466, 0.0040\n",
      "0.9678, 0.0541, 0.0043\n",
      "0.9611, 0.0613, 0.0046\n",
      "0.9723, 0.0488, 0.0040\n",
      "0.9762, 0.0408, 0.0038\n",
      "0.9768, 0.0404, 0.0038\n",
      "0.9756, 0.0420, 0.0038\n",
      "0.9715, 0.0478, 0.0041\n",
      "0.9689, 0.0501, 0.0042\n",
      "0.9741, 0.0449, 0.0039\n",
      "0.9590, 0.0623, 0.0047\n",
      "0.9727, 0.0467, 0.0040\n",
      "0.9772, 0.0412, 0.0037\n",
      "0.9559, 0.0683, 0.0048\n",
      "0.9575, 0.0684, 0.0047\n",
      "0.9466, 0.0776, 0.0053\n",
      "0.9653, 0.0565, 0.0044\n",
      "0.9697, 0.0501, 0.0042\n",
      "0.9694, 0.0502, 0.0042\n",
      "0.9625, 0.0611, 0.0045\n",
      "0.9569, 0.0671, 0.0048\n",
      "0.9651, 0.0552, 0.0044\n",
      "0.9766, 0.0418, 0.0038\n",
      "0.9769, 0.0406, 0.0038\n",
      "0.9604, 0.0620, 0.0047\n",
      "0.9701, 0.0495, 0.0041\n",
      "0.9711, 0.0473, 0.0041\n",
      "0.9604, 0.0620, 0.0047\n",
      "0.9676, 0.0550, 0.0043\n",
      "0.9681, 0.0523, 0.0043\n",
      "0.9732, 0.0458, 0.0040\n",
      "0.9083, 0.1214, 0.0066\n",
      "0.9717, 0.0498, 0.0040\n",
      "0.9666, 0.0556, 0.0043\n",
      "0.9671, 0.0554, 0.0043\n",
      "0.9602, 0.0626, 0.0046\n",
      "0.9734, 0.0461, 0.0040\n",
      "0.9688, 0.0529, 0.0042\n",
      "0.9726, 0.0463, 0.0040\n",
      "0.9685, 0.0518, 0.0042\n",
      "0.0326, 0.9298, 0.0585\n",
      "0.0351, 0.9166, 0.0650\n",
      "0.0298, 0.9112, 0.0784\n",
      "0.0291, 0.8334, 0.1435\n",
      "0.0289, 0.8885, 0.0988\n",
      "0.0286, 0.8142, 0.1632\n",
      "0.0324, 0.8824, 0.0954\n",
      "0.0584, 0.9016, 0.0481\n",
      "0.0317, 0.9228, 0.0659\n",
      "0.0387, 0.8406, 0.1103\n",
      "0.0368, 0.8974, 0.0766\n",
      "0.0375, 0.8993, 0.0731\n",
      "0.0330, 0.9242, 0.0627\n",
      "0.0274, 0.8285, 0.1548\n",
      "0.0593, 0.9040, 0.0457\n",
      "0.0348, 0.9280, 0.0566\n",
      "0.0280, 0.7154, 0.2440\n",
      "0.0374, 0.9239, 0.0576\n",
      "0.0205, 0.5987, 0.3966\n",
      "0.0370, 0.9168, 0.0625\n",
      "0.0210, 0.4191, 0.5552\n",
      "0.0380, 0.9229, 0.0560\n",
      "0.0181, 0.4377, 0.5693\n",
      "0.0291, 0.8765, 0.1105\n",
      "0.0346, 0.9259, 0.0588\n",
      "0.0339, 0.9263, 0.0593\n",
      "0.0289, 0.9050, 0.0854\n",
      "0.0232, 0.7409, 0.2483\n",
      "0.0291, 0.8398, 0.1382\n",
      "0.0498, 0.9142, 0.0475\n",
      "0.0372, 0.9146, 0.0637\n",
      "0.0399, 0.9206, 0.0559\n",
      "0.0396, 0.9201, 0.0563\n",
      "0.0144, 0.1672, 0.8454\n",
      "0.0262, 0.5812, 0.3693\n",
      "0.0398, 0.8848, 0.0789\n",
      "0.0313, 0.9158, 0.0717\n",
      "0.0278, 0.8773, 0.1112\n",
      "0.0431, 0.9043, 0.0625\n",
      "0.0328, 0.8727, 0.1023\n",
      "0.0274, 0.7814, 0.1968\n",
      "0.0308, 0.8800, 0.1018\n",
      "0.0360, 0.9173, 0.0634\n",
      "0.0518, 0.9079, 0.0503\n",
      "0.0328, 0.8720, 0.1035\n",
      "0.0406, 0.9126, 0.0609\n",
      "0.0373, 0.9015, 0.0730\n",
      "0.0349, 0.9212, 0.0621\n",
      "0.0879, 0.8772, 0.0381\n",
      "0.0372, 0.9053, 0.0702\n",
      "0.0119, 0.0799, 0.9297\n",
      "0.0128, 0.0948, 0.9145\n",
      "0.0121, 0.0978, 0.9143\n",
      "0.0126, 0.0998, 0.9120\n",
      "0.0119, 0.0838, 0.9269\n",
      "0.0116, 0.0843, 0.9274\n",
      "0.0147, 0.0980, 0.9043\n",
      "0.0121, 0.0963, 0.9165\n",
      "0.0120, 0.0895, 0.9225\n",
      "0.0120, 0.0892, 0.9213\n",
      "0.0170, 0.3150, 0.6873\n",
      "0.0127, 0.1124, 0.8995\n",
      "0.0128, 0.1199, 0.8922\n",
      "0.0124, 0.0866, 0.9224\n",
      "0.0124, 0.0807, 0.9264\n",
      "0.0130, 0.1018, 0.9062\n",
      "0.0135, 0.1425, 0.8707\n",
      "0.0121, 0.0987, 0.9138\n",
      "0.0115, 0.0802, 0.9312\n",
      "0.0134, 0.1328, 0.8805\n",
      "0.0122, 0.0971, 0.9138\n",
      "0.0134, 0.0951, 0.9109\n",
      "0.0116, 0.0835, 0.9283\n",
      "0.0159, 0.2710, 0.7386\n",
      "0.0128, 0.1100, 0.9012\n",
      "0.0137, 0.1688, 0.8470\n",
      "0.0176, 0.3588, 0.6431\n",
      "0.0176, 0.3237, 0.6758\n",
      "0.0120, 0.0858, 0.9249\n",
      "0.0163, 0.3424, 0.6735\n",
      "0.0122, 0.1033, 0.9098\n",
      "0.0158, 0.3193, 0.6965\n",
      "0.0119, 0.0837, 0.9267\n",
      "0.0183, 0.4334, 0.5732\n",
      "0.0131, 0.1086, 0.9052\n",
      "0.0118, 0.0967, 0.9155\n",
      "0.0125, 0.0843, 0.9232\n",
      "0.0137, 0.1424, 0.8701\n",
      "0.0185, 0.3556, 0.6373\n",
      "0.0141, 0.1831, 0.8297\n",
      "0.0120, 0.0873, 0.9226\n",
      "0.0152, 0.2346, 0.7742\n",
      "0.0128, 0.0948, 0.9145\n",
      "0.0119, 0.0859, 0.9248\n",
      "0.0120, 0.0850, 0.9244\n",
      "0.0131, 0.1249, 0.8853\n",
      "0.0131, 0.1289, 0.8828\n",
      "0.0142, 0.1725, 0.8385\n",
      "0.0132, 0.0929, 0.9128\n",
      "0.0144, 0.1431, 0.8649\n"
     ]
    }
   ],
   "source": [
    "iris_mlp = MLP(4,7,3)\n",
    "\n",
    "iris_mlp.train_inputs = training_inputs\n",
    "iris_mlp.train_outputs = training_outputs\n",
    "\n",
    "xs = training_inputs.T\n",
    "print(\"\\nOutputs Before Training:\\n\" + iris_mlp.feedforward(xs))\n",
    "print(\"cost = \", str(c[-1]))\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.8\n",
    "\n",
    "c = iris_mlp.train(epochs, learning_rate)\n",
    "print(\"cost = \", str(c[-1]))\n",
    "print(\"\\nOutputs after training:\\n\" + iris_mlp.feedforward(xs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
